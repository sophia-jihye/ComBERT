{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from glob import glob\n",
    "from reports import get_average_classification_report\n",
    "pd.options.display.float_format = '{:.2f}'.format\n",
    "from functools import reduce\n",
    "pd.options.display.float_format = '{:.2f}'.format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/media/dmlab/My Passport/DATA/ComBERT/result_bert-base-uncased',\n",
       " '/media/dmlab/My Passport/DATA/ComBERT/result_finbert',\n",
       " '/media/dmlab/My Passport/DATA/ComBERT/result_finbert-pretrain',\n",
       " '/media/dmlab/My Passport/DATA/ComBERT/result_pt_bert-base-uncased_with_company_masking_first=True',\n",
       " '/media/dmlab/My Passport/DATA/ComBERT/result_pt_bert-base-uncased_wo_company_masking_first=None',\n",
       " '/media/dmlab/My Passport/DATA/ComBERT/result_pt_finbert-pretrain_with_company_masking_first=True',\n",
       " '/media/dmlab/My Passport/DATA/ComBERT/result_pt_finbert-pretrain_wo_company_masking_first=None',\n",
       " '/media/dmlab/My Passport/DATA/ComBERT/result_pt_finbert_with_company_masking_first=True',\n",
       " '/media/dmlab/My Passport/DATA/ComBERT/result_pt_finbert_wo_company_masking_first=None',\n",
       " '/media/dmlab/My Passport/DATA/ComBERT/result_pt_sec-bert-base_with_company_masking_first=True',\n",
       " '/media/dmlab/My Passport/DATA/ComBERT/result_pt_sec-bert-base_wo_company_masking_first=None',\n",
       " '/media/dmlab/My Passport/DATA/ComBERT/result_sec-bert-base']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "root_dir = '/media/dmlab/My Passport/DATA/ComBERT'\n",
    "filepaths = sorted(glob(os.path.join(root_dir, 'result_*', 'classification_report_train_*.csv')))\n",
    "dirnames = sorted(list(set([os.path.dirname(filepath) for filepath in filepaths])))\n",
    "dirnames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Result\n",
    "* `yiyanghkust/finbert-pretrain`이 가장 좋은 성능을 보임\n",
    "> finbert-pretrain의 사전 학습 데이터: Corporate Reports 10-K & 10-Q: 2.5B tokens, Earnings Call Transcripts: 1.3B tokens, Analyst Reports: 1.1B tokens\n",
    "\n",
    "* `Company name masking`을 적용할 때 성능이 향상됨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created /media/dmlab/My Passport/DATA/ComBERT/classification_report.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BERT</th>\n",
       "      <th>FinBERT-Araci</th>\n",
       "      <th>FinBERT-Yang</th>\n",
       "      <th>BERT_pt_CM</th>\n",
       "      <th>BERT_pt_subword</th>\n",
       "      <th>FinBERT-Yang_pt_CM</th>\n",
       "      <th>FinBERT-Yang_pt_subword</th>\n",
       "      <th>FinBERT-Araci_pt_CM</th>\n",
       "      <th>FinBERT-Araci_pt_subword</th>\n",
       "      <th>SEC-BERT_pt_CM</th>\n",
       "      <th>SEC-BERT_pt_subword</th>\n",
       "      <th>SEC-BERT</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trained_with</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>55.70</td>\n",
       "      <td>17.27</td>\n",
       "      <td>50.60</td>\n",
       "      <td>59.57</td>\n",
       "      <td>49.00</td>\n",
       "      <td>64.06</td>\n",
       "      <td>52.94</td>\n",
       "      <td>59.25</td>\n",
       "      <td>53.83</td>\n",
       "      <td>64.52</td>\n",
       "      <td>59.60</td>\n",
       "      <td>64.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>60.24</td>\n",
       "      <td>32.20</td>\n",
       "      <td>47.54</td>\n",
       "      <td>56.21</td>\n",
       "      <td>49.51</td>\n",
       "      <td>63.59</td>\n",
       "      <td>53.54</td>\n",
       "      <td>56.74</td>\n",
       "      <td>59.11</td>\n",
       "      <td>59.75</td>\n",
       "      <td>59.15</td>\n",
       "      <td>66.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>400</th>\n",
       "      <td>62.26</td>\n",
       "      <td>41.49</td>\n",
       "      <td>48.54</td>\n",
       "      <td>67.98</td>\n",
       "      <td>50.74</td>\n",
       "      <td>72.70</td>\n",
       "      <td>58.82</td>\n",
       "      <td>60.21</td>\n",
       "      <td>60.96</td>\n",
       "      <td>67.41</td>\n",
       "      <td>62.61</td>\n",
       "      <td>60.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500</th>\n",
       "      <td>66.64</td>\n",
       "      <td>50.45</td>\n",
       "      <td>60.76</td>\n",
       "      <td>72.54</td>\n",
       "      <td>71.24</td>\n",
       "      <td>77.39</td>\n",
       "      <td>73.45</td>\n",
       "      <td>75.84</td>\n",
       "      <td>70.23</td>\n",
       "      <td>73.06</td>\n",
       "      <td>69.50</td>\n",
       "      <td>68.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>600</th>\n",
       "      <td>66.39</td>\n",
       "      <td>52.91</td>\n",
       "      <td>68.82</td>\n",
       "      <td>76.39</td>\n",
       "      <td>62.08</td>\n",
       "      <td>76.13</td>\n",
       "      <td>72.67</td>\n",
       "      <td>79.77</td>\n",
       "      <td>61.99</td>\n",
       "      <td>76.24</td>\n",
       "      <td>69.02</td>\n",
       "      <td>69.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>700</th>\n",
       "      <td>64.16</td>\n",
       "      <td>62.61</td>\n",
       "      <td>68.51</td>\n",
       "      <td>75.79</td>\n",
       "      <td>70.64</td>\n",
       "      <td>78.35</td>\n",
       "      <td>74.44</td>\n",
       "      <td>79.63</td>\n",
       "      <td>74.94</td>\n",
       "      <td>73.75</td>\n",
       "      <td>71.96</td>\n",
       "      <td>70.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>800</th>\n",
       "      <td>64.76</td>\n",
       "      <td>64.65</td>\n",
       "      <td>69.96</td>\n",
       "      <td>70.76</td>\n",
       "      <td>74.69</td>\n",
       "      <td>79.02</td>\n",
       "      <td>76.29</td>\n",
       "      <td>80.42</td>\n",
       "      <td>68.07</td>\n",
       "      <td>76.87</td>\n",
       "      <td>73.04</td>\n",
       "      <td>69.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>900</th>\n",
       "      <td>71.68</td>\n",
       "      <td>70.11</td>\n",
       "      <td>71.13</td>\n",
       "      <td>78.54</td>\n",
       "      <td>79.83</td>\n",
       "      <td>80.29</td>\n",
       "      <td>79.17</td>\n",
       "      <td>80.43</td>\n",
       "      <td>77.94</td>\n",
       "      <td>78.57</td>\n",
       "      <td>73.14</td>\n",
       "      <td>69.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000</th>\n",
       "      <td>73.14</td>\n",
       "      <td>73.41</td>\n",
       "      <td>74.50</td>\n",
       "      <td>77.32</td>\n",
       "      <td>80.26</td>\n",
       "      <td>80.63</td>\n",
       "      <td>78.74</td>\n",
       "      <td>80.47</td>\n",
       "      <td>79.77</td>\n",
       "      <td>80.37</td>\n",
       "      <td>74.29</td>\n",
       "      <td>74.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000</th>\n",
       "      <td>80.81</td>\n",
       "      <td>78.89</td>\n",
       "      <td>81.09</td>\n",
       "      <td>82.35</td>\n",
       "      <td>80.93</td>\n",
       "      <td>82.46</td>\n",
       "      <td>80.70</td>\n",
       "      <td>81.84</td>\n",
       "      <td>80.69</td>\n",
       "      <td>80.17</td>\n",
       "      <td>81.04</td>\n",
       "      <td>80.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10000</th>\n",
       "      <td>84.48</td>\n",
       "      <td>84.46</td>\n",
       "      <td>84.83</td>\n",
       "      <td>84.29</td>\n",
       "      <td>84.49</td>\n",
       "      <td>84.63</td>\n",
       "      <td>85.19</td>\n",
       "      <td>84.83</td>\n",
       "      <td>84.46</td>\n",
       "      <td>84.40</td>\n",
       "      <td>84.54</td>\n",
       "      <td>83.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20000</th>\n",
       "      <td>84.40</td>\n",
       "      <td>84.98</td>\n",
       "      <td>85.54</td>\n",
       "      <td>84.75</td>\n",
       "      <td>84.46</td>\n",
       "      <td>84.95</td>\n",
       "      <td>85.38</td>\n",
       "      <td>84.95</td>\n",
       "      <td>85.00</td>\n",
       "      <td>84.83</td>\n",
       "      <td>85.62</td>\n",
       "      <td>85.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40000</th>\n",
       "      <td>85.53</td>\n",
       "      <td>84.91</td>\n",
       "      <td>86.18</td>\n",
       "      <td>85.02</td>\n",
       "      <td>85.89</td>\n",
       "      <td>85.57</td>\n",
       "      <td>85.41</td>\n",
       "      <td>85.61</td>\n",
       "      <td>85.60</td>\n",
       "      <td>84.55</td>\n",
       "      <td>86.08</td>\n",
       "      <td>85.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Average</th>\n",
       "      <td>70.78</td>\n",
       "      <td>61.41</td>\n",
       "      <td>69.08</td>\n",
       "      <td>74.73</td>\n",
       "      <td>71.06</td>\n",
       "      <td>77.67</td>\n",
       "      <td>73.60</td>\n",
       "      <td>76.15</td>\n",
       "      <td>72.51</td>\n",
       "      <td>75.73</td>\n",
       "      <td>73.05</td>\n",
       "      <td>72.99</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              BERT  FinBERT-Araci  FinBERT-Yang  BERT_pt_CM  BERT_pt_subword  \\\n",
       "trained_with                                                                   \n",
       "200          55.70          17.27         50.60       59.57            49.00   \n",
       "300          60.24          32.20         47.54       56.21            49.51   \n",
       "400          62.26          41.49         48.54       67.98            50.74   \n",
       "500          66.64          50.45         60.76       72.54            71.24   \n",
       "600          66.39          52.91         68.82       76.39            62.08   \n",
       "700          64.16          62.61         68.51       75.79            70.64   \n",
       "800          64.76          64.65         69.96       70.76            74.69   \n",
       "900          71.68          70.11         71.13       78.54            79.83   \n",
       "1000         73.14          73.41         74.50       77.32            80.26   \n",
       "2000         80.81          78.89         81.09       82.35            80.93   \n",
       "10000        84.48          84.46         84.83       84.29            84.49   \n",
       "20000        84.40          84.98         85.54       84.75            84.46   \n",
       "40000        85.53          84.91         86.18       85.02            85.89   \n",
       "Average      70.78          61.41         69.08       74.73            71.06   \n",
       "\n",
       "              FinBERT-Yang_pt_CM  FinBERT-Yang_pt_subword  \\\n",
       "trained_with                                                \n",
       "200                        64.06                    52.94   \n",
       "300                        63.59                    53.54   \n",
       "400                        72.70                    58.82   \n",
       "500                        77.39                    73.45   \n",
       "600                        76.13                    72.67   \n",
       "700                        78.35                    74.44   \n",
       "800                        79.02                    76.29   \n",
       "900                        80.29                    79.17   \n",
       "1000                       80.63                    78.74   \n",
       "2000                       82.46                    80.70   \n",
       "10000                      84.63                    85.19   \n",
       "20000                      84.95                    85.38   \n",
       "40000                      85.57                    85.41   \n",
       "Average                    77.67                    73.60   \n",
       "\n",
       "              FinBERT-Araci_pt_CM  FinBERT-Araci_pt_subword  SEC-BERT_pt_CM  \\\n",
       "trained_with                                                                  \n",
       "200                         59.25                     53.83           64.52   \n",
       "300                         56.74                     59.11           59.75   \n",
       "400                         60.21                     60.96           67.41   \n",
       "500                         75.84                     70.23           73.06   \n",
       "600                         79.77                     61.99           76.24   \n",
       "700                         79.63                     74.94           73.75   \n",
       "800                         80.42                     68.07           76.87   \n",
       "900                         80.43                     77.94           78.57   \n",
       "1000                        80.47                     79.77           80.37   \n",
       "2000                        81.84                     80.69           80.17   \n",
       "10000                       84.83                     84.46           84.40   \n",
       "20000                       84.95                     85.00           84.83   \n",
       "40000                       85.61                     85.60           84.55   \n",
       "Average                     76.15                     72.51           75.73   \n",
       "\n",
       "              SEC-BERT_pt_subword  SEC-BERT  \n",
       "trained_with                                 \n",
       "200                         59.60     64.50  \n",
       "300                         59.15     66.16  \n",
       "400                         62.61     60.86  \n",
       "500                         69.50     68.20  \n",
       "600                         69.02     69.79  \n",
       "700                         71.96     70.58  \n",
       "800                         73.04     69.41  \n",
       "900                         73.14     69.08  \n",
       "1000                        74.29     74.72  \n",
       "2000                        81.04     80.44  \n",
       "10000                       84.54     83.93  \n",
       "20000                       85.62     85.54  \n",
       "40000                       86.08     85.70  \n",
       "Average                     73.05     72.99  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_df(filepaths, colname):\n",
    "    records = []\n",
    "    for report_filepath in filepaths:\n",
    "        mode = os.path.basename(report_filepath).split('_')[-1].replace('.csv', '')\n",
    "        df = pd.read_csv(report_filepath).set_index('Unnamed: 0')\n",
    "        acc = 100*df.filter(items = ['accuracy'], axis=0)['f1-score'].values[0]\n",
    "        records.append((int(mode), acc))\n",
    "    return pd.DataFrame(records, columns=['trained_with', colname]).sort_values(by=['trained_with'])\n",
    "\n",
    "dfs = []\n",
    "for dirname in dirnames:\n",
    "    filepaths = glob(os.path.join(dirname, 'classification_report_*.csv'))\n",
    "    filepaths = [item for item in filepaths if int(item.split('_')[-1].replace('.csv', ''))>=200]\n",
    "# #     filepaths = [item for item in filepaths if int(item.split('_')[-1].replace('.csv', ''))<40000]\n",
    "    name = os.path.basename(dirname.replace('result_', ''))\n",
    "    df = get_df(filepaths, name)    \n",
    "    dfs.append(df)    \n",
    "result = reduce(lambda df1,df2: pd.merge(df1,df2,on='trained_with'), dfs)\n",
    "result.set_index('trained_with', inplace=True)\n",
    "result.loc['Average'] = result.mean()\n",
    "\n",
    "dict_to_rename_columns = {'bert-base-uncased': 'BERT', 'finbert': 'FinBERT-Araci', 'finbert-pretrain': 'FinBERT-Yang',\n",
    "       'pt_bert-base-uncased_with_company_masking_first=True': 'BERT_pt_CM',\n",
    "       'pt_bert-base-uncased_wo_company_masking_first=None': 'BERT_pt_subword',\n",
    "       'pt_finbert-pretrain_with_company_masking_first=True': 'FinBERT-Yang_pt_CM',\n",
    "       'pt_finbert-pretrain_wo_company_masking_first=None': 'FinBERT-Yang_pt_subword',\n",
    "       'pt_finbert_with_company_masking_first=True': 'FinBERT-Araci_pt_CM',\n",
    "       'pt_finbert_wo_company_masking_first=None': 'FinBERT-Araci_pt_subword',\n",
    "       'pt_sec-bert-base_with_company_masking_first=True': 'SEC-BERT_pt_CM',\n",
    "       'pt_sec-bert-base_wo_company_masking_first=None': 'SEC-BERT_pt_subword', 'sec-bert-base': 'SEC-BERT'}\n",
    "new_colnames = [dict_to_rename_columns[item] for item in result.columns]\n",
    "result.columns = new_colnames\n",
    "\n",
    "filepath = os.path.join(root_dir, 'classification_report.csv')\n",
    "result.to_csv(filepath)\n",
    "print('Created {}'.format(filepath))\n",
    "\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* `Company name masking`의 성능 향상 효과는 finetuning 데이터가 적을 때 특히 더 효과적으로 작용함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created /media/dmlab/My Passport/DATA/ComBERT/classification_report_Low.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BERT</th>\n",
       "      <th>FinBERT-Araci</th>\n",
       "      <th>FinBERT-Yang</th>\n",
       "      <th>BERT_pt_CM</th>\n",
       "      <th>BERT_pt_subword</th>\n",
       "      <th>FinBERT-Yang_pt_CM</th>\n",
       "      <th>FinBERT-Yang_pt_subword</th>\n",
       "      <th>FinBERT-Araci_pt_CM</th>\n",
       "      <th>FinBERT-Araci_pt_subword</th>\n",
       "      <th>SEC-BERT_pt_CM</th>\n",
       "      <th>SEC-BERT_pt_subword</th>\n",
       "      <th>SEC-BERT</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trained_with</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>55.70</td>\n",
       "      <td>17.27</td>\n",
       "      <td>50.60</td>\n",
       "      <td>59.57</td>\n",
       "      <td>49.00</td>\n",
       "      <td>64.06</td>\n",
       "      <td>52.94</td>\n",
       "      <td>59.25</td>\n",
       "      <td>53.83</td>\n",
       "      <td>64.52</td>\n",
       "      <td>59.60</td>\n",
       "      <td>64.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>60.24</td>\n",
       "      <td>32.20</td>\n",
       "      <td>47.54</td>\n",
       "      <td>56.21</td>\n",
       "      <td>49.51</td>\n",
       "      <td>63.59</td>\n",
       "      <td>53.54</td>\n",
       "      <td>56.74</td>\n",
       "      <td>59.11</td>\n",
       "      <td>59.75</td>\n",
       "      <td>59.15</td>\n",
       "      <td>66.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>400</th>\n",
       "      <td>62.26</td>\n",
       "      <td>41.49</td>\n",
       "      <td>48.54</td>\n",
       "      <td>67.98</td>\n",
       "      <td>50.74</td>\n",
       "      <td>72.70</td>\n",
       "      <td>58.82</td>\n",
       "      <td>60.21</td>\n",
       "      <td>60.96</td>\n",
       "      <td>67.41</td>\n",
       "      <td>62.61</td>\n",
       "      <td>60.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500</th>\n",
       "      <td>66.64</td>\n",
       "      <td>50.45</td>\n",
       "      <td>60.76</td>\n",
       "      <td>72.54</td>\n",
       "      <td>71.24</td>\n",
       "      <td>77.39</td>\n",
       "      <td>73.45</td>\n",
       "      <td>75.84</td>\n",
       "      <td>70.23</td>\n",
       "      <td>73.06</td>\n",
       "      <td>69.50</td>\n",
       "      <td>68.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>600</th>\n",
       "      <td>66.39</td>\n",
       "      <td>52.91</td>\n",
       "      <td>68.82</td>\n",
       "      <td>76.39</td>\n",
       "      <td>62.08</td>\n",
       "      <td>76.13</td>\n",
       "      <td>72.67</td>\n",
       "      <td>79.77</td>\n",
       "      <td>61.99</td>\n",
       "      <td>76.24</td>\n",
       "      <td>69.02</td>\n",
       "      <td>69.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>700</th>\n",
       "      <td>64.16</td>\n",
       "      <td>62.61</td>\n",
       "      <td>68.51</td>\n",
       "      <td>75.79</td>\n",
       "      <td>70.64</td>\n",
       "      <td>78.35</td>\n",
       "      <td>74.44</td>\n",
       "      <td>79.63</td>\n",
       "      <td>74.94</td>\n",
       "      <td>73.75</td>\n",
       "      <td>71.96</td>\n",
       "      <td>70.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>800</th>\n",
       "      <td>64.76</td>\n",
       "      <td>64.65</td>\n",
       "      <td>69.96</td>\n",
       "      <td>70.76</td>\n",
       "      <td>74.69</td>\n",
       "      <td>79.02</td>\n",
       "      <td>76.29</td>\n",
       "      <td>80.42</td>\n",
       "      <td>68.07</td>\n",
       "      <td>76.87</td>\n",
       "      <td>73.04</td>\n",
       "      <td>69.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>900</th>\n",
       "      <td>71.68</td>\n",
       "      <td>70.11</td>\n",
       "      <td>71.13</td>\n",
       "      <td>78.54</td>\n",
       "      <td>79.83</td>\n",
       "      <td>80.29</td>\n",
       "      <td>79.17</td>\n",
       "      <td>80.43</td>\n",
       "      <td>77.94</td>\n",
       "      <td>78.57</td>\n",
       "      <td>73.14</td>\n",
       "      <td>69.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Average</th>\n",
       "      <td>63.98</td>\n",
       "      <td>48.96</td>\n",
       "      <td>60.73</td>\n",
       "      <td>69.72</td>\n",
       "      <td>63.47</td>\n",
       "      <td>73.94</td>\n",
       "      <td>67.67</td>\n",
       "      <td>71.54</td>\n",
       "      <td>65.88</td>\n",
       "      <td>71.27</td>\n",
       "      <td>67.25</td>\n",
       "      <td>67.32</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              BERT  FinBERT-Araci  FinBERT-Yang  BERT_pt_CM  BERT_pt_subword  \\\n",
       "trained_with                                                                   \n",
       "200          55.70          17.27         50.60       59.57            49.00   \n",
       "300          60.24          32.20         47.54       56.21            49.51   \n",
       "400          62.26          41.49         48.54       67.98            50.74   \n",
       "500          66.64          50.45         60.76       72.54            71.24   \n",
       "600          66.39          52.91         68.82       76.39            62.08   \n",
       "700          64.16          62.61         68.51       75.79            70.64   \n",
       "800          64.76          64.65         69.96       70.76            74.69   \n",
       "900          71.68          70.11         71.13       78.54            79.83   \n",
       "Average      63.98          48.96         60.73       69.72            63.47   \n",
       "\n",
       "              FinBERT-Yang_pt_CM  FinBERT-Yang_pt_subword  \\\n",
       "trained_with                                                \n",
       "200                        64.06                    52.94   \n",
       "300                        63.59                    53.54   \n",
       "400                        72.70                    58.82   \n",
       "500                        77.39                    73.45   \n",
       "600                        76.13                    72.67   \n",
       "700                        78.35                    74.44   \n",
       "800                        79.02                    76.29   \n",
       "900                        80.29                    79.17   \n",
       "Average                    73.94                    67.67   \n",
       "\n",
       "              FinBERT-Araci_pt_CM  FinBERT-Araci_pt_subword  SEC-BERT_pt_CM  \\\n",
       "trained_with                                                                  \n",
       "200                         59.25                     53.83           64.52   \n",
       "300                         56.74                     59.11           59.75   \n",
       "400                         60.21                     60.96           67.41   \n",
       "500                         75.84                     70.23           73.06   \n",
       "600                         79.77                     61.99           76.24   \n",
       "700                         79.63                     74.94           73.75   \n",
       "800                         80.42                     68.07           76.87   \n",
       "900                         80.43                     77.94           78.57   \n",
       "Average                     71.54                     65.88           71.27   \n",
       "\n",
       "              SEC-BERT_pt_subword  SEC-BERT  \n",
       "trained_with                                 \n",
       "200                         59.60     64.50  \n",
       "300                         59.15     66.16  \n",
       "400                         62.61     60.86  \n",
       "500                         69.50     68.20  \n",
       "600                         69.02     69.79  \n",
       "700                         71.96     70.58  \n",
       "800                         73.04     69.41  \n",
       "900                         73.14     69.08  \n",
       "Average                     67.25     67.32  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "low = result.filter(items = [200, 300, 400, 500, 600, 700, 800, 900], axis=0)\n",
    "low.loc['Average'] = low.mean()\n",
    "\n",
    "filepath = os.path.join(root_dir, 'classification_report_Low.csv')\n",
    "low.to_csv(filepath)\n",
    "print('Created {}'.format(filepath))\n",
    "\n",
    "low"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
